git clone -b r23.06 https://github.com/triton-inference-server/server.git

sudo apt-get install -y docker nvidia-container-toolkit
sudo apt install -y nvidia-docker2  
sudo systemctl daemon-reload  
sudo systemctl restart docker

sudo ufw allow 8000
sudo ufw allow 8001
sudo ufw allow 8002

cd server/docs/examples
./fetch_models.sh

docker run --gpus=1 --rm -p8000:8000 -p8001:8001 -p8002:8002 --net=host -v ${PWD}/model_repository:/models nvcr.io/nvidia/tritonserver:23.06-py3 tritonserver --model-repository=/models
